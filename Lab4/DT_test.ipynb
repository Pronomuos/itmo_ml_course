{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGClrhQA9SAk"
   },
   "source": [
    "# Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veekMy8WRjBi"
   },
   "source": [
    "## Построение дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYkVwAFiUHXj"
   },
   "source": [
    "Опишем жадный алгоритм построения бинарного дерева решений:\n",
    "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n",
    "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n",
    "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
    "\n",
    "Функция $SplitNode(m, R_m)$\n",
    "1. Если выполнен критерий остановки, то выход.\n",
    "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
    "3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
    "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
    "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
    "\n",
    "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
    "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P6FsdBog4Ai"
   },
   "source": [
    "## Функционал качества для деревьев решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VAKO0aykGBD"
   },
   "source": [
    "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
    "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5582B-1Fn2bw"
   },
   "source": [
    "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n",
    "\n",
    "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1637575440357,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "PbcMUd7bvk05"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AdLxP9CowTm"
   },
   "source": [
    "Код для расчёта энтропии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2mT8Jq8Av2sM"
   },
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk9etb2vo7fK"
   },
   "source": [
    "Здесь $y$ - это массив значений целевой переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07TCw0USzLus"
   },
   "source": [
    "Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n",
    "\n",
    "Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n",
    "$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n",
    "\n",
    "На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trEWHDoXg_p9"
   },
   "source": [
    "Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер. \n",
    "\n",
    "$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n",
    "\n",
    "где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xmN6V_N1xBr"
   },
   "source": [
    "\n",
    "### Задание 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWFHZScF2CBF"
   },
   "source": [
    "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения дерева (используйте `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признакоd и порогов), для проверки критерия остановки.\n",
    "\n",
    "Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n",
    "* максимальной глубины дерева = 5\n",
    "* минимального числа объектов в листе = 5\n",
    "* максимальное количество листьев в дереве = 5\n",
    "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
    "\n",
    "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
    "\n",
    "Оцените точность каждой модели с помощью метрики точность (`from sklearn.metrics import accuracy_score` или реализовать свою)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1637575446421,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "mpVk9YtsGxP8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG8GJKrZqbwq"
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, X=None, depth=0):\n",
    "        self.X = X\n",
    "        self.depth = depth\n",
    "        self.split_param = None\n",
    "        self.target_value = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "\n",
    "    def target(self):\n",
    "        if self.target_value is None:\n",
    "            targets, counts = np.unique(self.X.iloc[:, -1], return_counts=True)\n",
    "            best_target = (-1, float('-inf'))\n",
    "            for target, prop in zip(targets, counts):\n",
    "                if prop > best_target[1]:\n",
    "                    best_target = (target, prop)\n",
    "            self.target_value = best_target[0]\n",
    "        return self.target_value\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy_val = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy_val\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier(object):\n",
    "\n",
    "    def __init__(self, max_depth=-1, min_samples_leaf=1, max_leaf_nodes=-1, purity=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.purity = purity\n",
    "\n",
    "        self.root = Node()\n",
    "        self.size = 1\n",
    "        self.next_nodes = deque()\n",
    "\n",
    "    def split(self, X, j, t):\n",
    "        sample1 = X[X.iloc[:, j] < t]\n",
    "        sample2 = X[X.iloc[:, j] >= t]\n",
    "\n",
    "        return sample1, sample2\n",
    "\n",
    "    def calc_ig(self, r_v, r_left, r_right):\n",
    "        r_left_prop = len(r_left) / len(r_v)\n",
    "        r_right_prop = len(r_right) / len(r_v)\n",
    "        return entropy(r_v) - \\\n",
    "               (r_left_prop * entropy(r_left) + r_right_prop * entropy(r_right))\n",
    "\n",
    "    def find_best_split(self, X):\n",
    "        best_values = (float('-inf'), -1, -1)\n",
    "        param_n = X.shape[1] - 1\n",
    "        for j in range(param_n):\n",
    "            min_value = X.iloc[:, j].min()\n",
    "            max_value = X.iloc[:, j].max()\n",
    "            values = np.linspace(min_value, max_value, num=10)\n",
    "            for t in values:\n",
    "                r_left, r_right = self.split(X, j, t)\n",
    "                ig = self.calc_ig(X.iloc[:, -1], r_left.iloc[:, -1], r_right.iloc[:, -1])\n",
    "                if ig > best_values[0]:\n",
    "                    best_values = (ig, j, t)\n",
    "        return best_values[1], best_values[2]\n",
    "\n",
    "    def check_purity(self, X):\n",
    "        targets = np.unique(X)\n",
    "        return len(targets) == 1\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
    "        self.root.X = X\n",
    "        self.next_nodes.append(self.root)\n",
    "\n",
    "        while len(self.next_nodes) > 0:\n",
    "            cur_node = self.next_nodes.popleft()\n",
    "            if cur_node.depth == self.max_depth:\n",
    "                continue\n",
    "            if cur_node.X.shape[0] <= self.min_samples_leaf:\n",
    "                continue\n",
    "            if self.purity and self.check_purity(cur_node.X.iloc[:, -1]):\n",
    "                continue\n",
    "\n",
    "            j, t = self.find_best_split(cur_node.X)\n",
    "            cur_node.split_param = (j, t)\n",
    "            r_left, r_right = self.split(cur_node.X, j, t)\n",
    "\n",
    "            left_node = Node(r_left, cur_node.depth + 1)\n",
    "            cur_node.left_child = left_node\n",
    "            self.next_nodes.append(left_node)\n",
    "            self.size += 1\n",
    "            if self.size == self.max_leaf_nodes:\n",
    "                self.next_nodes.clear()\n",
    "                break\n",
    "\n",
    "            right_node = Node(r_right, cur_node.depth + 1)\n",
    "            cur_node.right_child = right_node\n",
    "            self.next_nodes.append(right_node)\n",
    "            self.size += 1\n",
    "            if self.size == self.max_leaf_nodes:\n",
    "                self.next_nodes.clear()\n",
    "                break\n",
    "\n",
    "    def calc_final_node(self, node):\n",
    "        if node.left_child is None and node.right_child is None:\n",
    "            node.target()\n",
    "\n",
    "        if node.left_child is not None:\n",
    "            self.calc_final_node(node.left_child)\n",
    "\n",
    "        if node.right_child is not None:\n",
    "            self.calc_final_node(node.right_child)\n",
    "\n",
    "    def get_target(self, obj, node):\n",
    "        if node.right_child is None and node.left_child is None:\n",
    "            return node.target()\n",
    "\n",
    "        j, t = node.split_param\n",
    "\n",
    "        if obj[j] >= t:\n",
    "            return self.get_target(obj, node.right_child)\n",
    "        else:\n",
    "            return self.get_target(obj, node.left_child)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return [self.get_target(X_test[i, :], self.root) for i in range(len(X_test))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2676,
     "status": "ok",
     "timestamp": 1636703662624,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "HYs5LYlZHGp1",
    "outputId": "df485026-5262-442c-8314-dee77f07e790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with purity - 0.8333333333333334\n",
      "Accuracy with max depth 5 - 0.8666666666666667\n",
      "Accuracy with 15 leaf nodes - 0.9\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(purity=True)\n",
    "tree.fit(X_train, y_train)\n",
    "print('Accuracy with purity -', accuracy_score(tree.predict(X_test), y_test))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "print('Accuracy with max depth 5 -', accuracy_score(tree.predict(X_test), y_test))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "tree.fit(X_train, y_train)\n",
    "print('Accuracy with 15 leaf nodes -', accuracy_score(tree.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkyCjLcy_CTM"
   },
   "source": [
    "##  Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fKZe1FyRgCa"
   },
   "source": [
    "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
    "\n",
    "1. Зададим $N$ - число деревьев в лесу.\n",
    "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
    "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
    "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJBQ8lc0WyrN"
   },
   "source": [
    "### Задание 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y594Jn04ZTCm"
   },
   "source": [
    "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
    "\n",
    "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_mLbdVW2oG"
   },
   "source": [
    "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n",
    "\n",
    "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
    "\n",
    "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
    "\n",
    "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1637575454592,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "qicKl6g2JD7y"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class RandomForest(BaseEstimator):\n",
    "    estimators = list()\n",
    "\n",
    "    def __init__(self, base_estimator=DecisionTreeClassifier, max_features='sqrt',\n",
    "                 n_estimators=10, max_depth=None, min_samples_leaf=1, max_leaf_nodes=None, criterion='gini'):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.max_features = max_features\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_boostrap_sample(self, sample):\n",
    "        new_sample = np.empty([sample.shape[0], sample.shape[1]])\n",
    "        n_sample = sample.shape[0]\n",
    "        for i in range(n_sample):\n",
    "            index = randrange(n_sample)\n",
    "            new_sample[i] = sample[index]\n",
    "        return new_sample\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.n_estimators):\n",
    "            Xy = np.hstack((X, y.reshape(-1, 1)))\n",
    "            new_Xy = self.get_boostrap_sample(Xy)\n",
    "            new_X_train, new_y_train = new_Xy[:, :-1], new_Xy[:, -1].flatten()\n",
    "            estimator = self.base_estimator(max_features=self.max_features, max_depth=self.max_depth,\n",
    "                                            min_samples_leaf=self.min_samples_leaf, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                            criterion=self.criterion)\n",
    "            estimator.fit(new_X_train, new_y_train)\n",
    "            self.estimators.append(estimator)\n",
    "        return self\n",
    "\n",
    "    def predict_obj(self, pred_obj):\n",
    "        values, counts = np.unique(pred_obj, return_counts=True)\n",
    "        ind = np.argmax(counts)\n",
    "        return values[ind]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = np.array([estimator.predict(X_test) for estimator in self.estimators])\n",
    "        return [self.predict_obj(predictions[:, i]) for i in range(X_test.shape[0])]\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        pred_y = self.predict(X_test)\n",
    "        return accuracy_score(pred_y, y_test)\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'base_estimator': self.base_estimator,\n",
    "                'max_features': self.max_features,\n",
    "                'n_estimators': self.n_estimators,\n",
    "                'max_depth': self.max_depth,\n",
    "                'min_samples_leaf': self.min_samples_leaf,\n",
    "                'max_leaf_nodes': self.max_leaf_nodes,\n",
    "                'criterion': self.criterion}\n",
    "\n",
    "    def set_params(self, params):\n",
    "        for parameter, value in params:\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def get_feature_informativeness(self, X, y):\n",
    "        informativeness_matrix = np.empty((self.n_estimators, X.shape[1]))\n",
    "        for i in range(self.n_estimators):\n",
    "            Xy = np.hstack((X, y.reshape(-1, 1)))\n",
    "            new_Xy = self.get_boostrap_sample(Xy)\n",
    "            new_X_train, new_y_train = new_Xy[:, :-1], new_Xy[:, -1].flatten()\n",
    "            estimator = self.base_estimator(max_features=self.max_features, max_depth=self.max_depth,\n",
    "                                            min_samples_leaf=self.min_samples_leaf, max_leaf_nodes=self.max_leaf_nodes,\n",
    "                                            criterion=self.criterion)\n",
    "            estimator.fit(new_X_train, new_y_train)\n",
    "            oob_Xy = np.array([obj for obj in Xy if not any(np.equal(new_Xy, obj).all(1))])\n",
    "            oob_X_test, oob_y_test = oob_Xy[:, :-1], oob_Xy[:, -1].flatten()\n",
    "            pred_y = estimator.predict(oob_X_test)\n",
    "            initial_q = accuracy_score(pred_y, oob_y_test)\n",
    "            for j in range(oob_X_test.shape[1]):\n",
    "                noise = np.array([randrange(-1000, 1000) for _ in range(oob_X_test.shape[0])])\n",
    "                oob_X_test_copy = oob_X_test.copy()\n",
    "                oob_X_test_copy[:, j] = noise\n",
    "                noise_pred_y = estimator.predict(oob_X_test_copy)\n",
    "                noise_q = accuracy_score(noise_pred_y, oob_y_test)\n",
    "                informativeness_matrix[i, j] = initial_q - noise_q\n",
    "        return np.mean(informativeness_matrix, axis=0).argsort()[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1637575459398,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "Yr3IaX7T-0Nf"
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "class GridSearch(object):\n",
    "    best_score_ = float(\"-inf\")\n",
    "    best_params_ = None\n",
    "\n",
    "    def __init__(self, checked_estimator, params, scoring, cv):\n",
    "        self.checked_estimator = checked_estimator\n",
    "        self.params = params\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        param_combs = [[list(el) for el in zip(self.params.keys(), comb)]\n",
    "                       for comb in it.product(*(self.params[key] for key in self.params.keys()))]\n",
    "        for params in param_combs:\n",
    "            estimator = self.checked_estimator()\n",
    "            estimator.set_params(params)\n",
    "            score = cross_val_score(estimator, X, y, scoring=self.scoring, cv=self.cv).mean()\n",
    "            if self.best_score_ < score:\n",
    "                self.best_score_ = score\n",
    "                self.best_params_ = params\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1637575462686,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "8MYjd0XAjPRa"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1637575463146,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "fajMM4_qCl3S",
    "outputId": "b3ac8cb5-3b66-4bd5-99a2-323270d85a49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e6FjJ3TywRw"
   },
   "source": [
    "При обучении модели не будем учитывать признаки RowNumber, CustomerId Surname, так как они не влияют на то, покинет ли клиент банк (являются по сути шумовыми)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1637575466583,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "Ji-T_7phDG89"
   },
   "outputs": [],
   "source": [
    "categorical_data = df[['Geography', 'Gender']]\n",
    "numertical_binary_data = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary','HasCrCard', 'IsActiveMember']].to_numpy()\n",
    "y = df['Exited'].to_numpy()\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_data = encoder.fit_transform(categorical_data).toarray()\n",
    "X = np.hstack((numertical_binary_data, categorical_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1637575469368,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "qp3Ozi1N_ibZ",
    "outputId": "64d75505-e6e8-4d3b-8bd3-a00a2d0b131f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9109063275853679\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(RandomForest(), X, y, cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAR47Dyn0B1m"
   },
   "source": [
    "Найдем науличшие гиперпараметры с помощью grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 702293,
     "status": "ok",
     "timestamp": 1637576173336,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "6-WHpiMe_AjA",
    "outputId": "76977168-dee0-4011-d846-6079c4d3d600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9539999290870899\n",
      "[['n_estimators', 1], ['min_samples_leaf', 1], ['criterion', 'gini'], ['max_depth', 10]]\n"
     ]
    }
   ],
   "source": [
    "forest_params = {'n_estimators': np.arange(1, 30, 5), \n",
    "                 'min_samples_leaf': np.arange(1, 20, 5),\n",
    "                 'criterion': ['gini','entropy'],\n",
    "                 'max_depth': np.arange(10, 40, 10)}\n",
    "\n",
    "forest_grid = GridSearch(RandomForest, forest_params, scoring='accuracy', cv=3)\n",
    "forest_grid.fit(X, y)\n",
    "print(forest_grid.best_score_)\n",
    "print(forest_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAzGkcF60OLY"
   },
   "source": [
    "Таким образом, при следующих гиперпараметрах [['n_estimators', 1], ['min_samples_leaf', 1], ['criterion', 'gini'], ['max_depth', 10]] модель дает наибольшую точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwEf3_ovt7Ml"
   },
   "source": [
    "Метод оценивания информативности признаков заключается в следующем: ошибку Qn базового дерева bn оценивают по out-of-bag выборке и запоминают. После этого признак j превращают в абсолютно бесполезный, шумовой: в матрицу «объекты-признаки» все значения в столбце j перемешивают. Затем то же самое дерево bn применяют к данной выборке с перемешанным признаком j и оценивают качество дерева на out-of-bag-подвыборке. Q′n — ошибка out-of-bag-подвыборке, она будет тем больше, чем сильнее дерево использует признак j. Если он активно используется в дереве, то ошибка сильно уменьшится, поскольку значение данного признака испорчено. Если же данный признак совершенно не важен для дерева и не используется в нем, то ошибка практически не изменится. Таким образом, информативность признака j оценивают как разность\n",
    "Q ′n − Q n .\n",
    "Далее эти информативности усредняют по всем деревьям случайного леса, и чем больше будет среднее значе- ние, тем важнее признак. На практике оказывается, что информативности, вычисленные описанным образом, и информативности, вычисленные как сумма уменьшения критерия информативности, оказываются очень связаны между собой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41279,
     "status": "ok",
     "timestamp": 1637334259904,
     "user": {
      "displayName": "Роман Решетников",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04257737993301595317"
     },
     "user_tz": -180
    },
    "id": "R27n3vOAWuXs",
    "outputId": "cb75996d-e3a6-4ee9-e2f5-e2aa4fc45a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  0  1  5  7  2  3  9  8 11 10  6 12]\n"
     ]
    }
   ],
   "source": [
    "print(forest.get_feature_informativeness(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0kv1FXqualM"
   },
   "source": [
    "Мы получили вектор индексов признаков в порядке убывания их значимости. Таким образом, Balance, Age, NumOfProducts, EstimatedSalary, IsActiveMember являются самыми информативными (5 первых признаков из вектора). "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Решетников Роман М33051 \"DT_test.ipynb\"",
   "provenance": [
    {
     "file_id": "1eUpBIYzwvrMx-cgqAn-mNMPza9U8_gZW",
     "timestamp": 1636575258875
    },
    {
     "file_id": "1IAJXJC3FAdrLQnl2yVoEvX8jg27CzLm6",
     "timestamp": 1603282414216
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
